Analysis step
    objective -- convert doc to inverted index and store in shard
    inverted index -- tokens and occurrences (philosophically it seems like it should be types and tokens)
    white space etc. (un-necessary information) is discarded to yield tokens
        examples
            stop words ("the")
            case (dog = Dog)
            stems (?) (swimming = swimmer)
            synonyms (?) (thin = skinny)
                stems and synonyms would both involve deriving tokens from equivalence classes
        seems like this could involve post-processing of an initial inverted index
    major steps (text => analyzer => tokens => inverted index)
        tokenization
        filtration 
How does analysis relate to querying (searching)?
    say we want to MATCH some text -- we will also analyze the text to match
    next lesson -- how to configure an analyzer for a field
the analyzer is applied at the "document" level
    the field to be analyzed is specified (we could potentially use this for the attributes field)
        settings / mappings for the index -- this is the proper way to create and populate an index in production